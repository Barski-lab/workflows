cwlVersion: v1.0
class: Workflow


requirements:
  - class: StepInputExpressionRequirement
  - class: MultipleInputFeatureRequirement
  - class: InlineJavascriptRequirement
    expressionLib:
    - var get_root = function(basename) {
          return basename.split('.').slice(0,1).join('.');
      };


inputs:

  fastq_file_1:
    type: File
    doc: "Paired-end sequencing data 1 in FASTQ format (fastq, fq, bzip2, gzip, zip)"

  fastq_file_2:
    type: File
    doc: "Paired-end sequencing data 2 in FASTQ format (fastq, fq, bzip2, gzip, zip)"

  indices_folder:
    type: Directory
    doc: "Directory with the genome indices generated by STAR"

  exclude_chromosome:
    type: string?
    default: "chrM chrY chrX"
    doc: "Case-sensitive space-separated chromosome list to be excluded"

  blacklisted_regions_bed:
    type: File
    doc: "Blacklisted genomic regions file in BED format"

  genome_size:
    type: string
    doc: "The length of the mappable genome (hs, mm, ce, dm or number, for example 2.7e9)"

  genome_fasta_file:
    type: File
    secondaryFiles:
    - .fai
    doc: "Reference genome sequence FASTA and FAI index files"

  threads:
    type: int?
    default: 4
    doc: "Number of threads for those steps that support multithreading"


outputs:

  fastqc_report_fastq_1:
    type: File
    outputSource: rename_fastqc_report_fastq_1/target_file

  fastqc_report_fastq_2:
    type: File
    outputSource: rename_fastqc_report_fastq_2/target_file

  trimgalore_report_fastq_1:
    type: File
    outputSource: trim_adapters/report_file

  trimgalore_report_fastq_2:
    type: File
    outputSource: trim_adapters/report_file_pair
  
  star_alignment_report:
    type: File
    outputSource: align_reads/log_final

  star_progress_report:
    type: File
    outputSource: align_reads/log_progress

  bam_statistics_report_after_alignment:
    type: File
    outputSource: get_bam_statistics/log_file

  samtools_markdup_report:
    type: File
    outputSource: remove_duplicates/markdup_report

  bam_statistics_report_after_filtering_and_dedup:
    type: File
    outputSource: get_bam_statistics_after_filtering/log_file

  filtered_deduplicated_reads_as_bam:
    type: File
    outputSource: remove_duplicates/deduplicated_bam_bai_pair

  filtered_deduplicated_reads_as_bed:
    type: File
    outputSource: convert_bam_to_bed/bed_file

  filtered_deduplicated_shifted_reads_as_bed:
    type: File
    outputSource: shift_reads/output_file

  filtered_deduplicated_sorted_shifted_reads_wo_blisted_as_bed:
    type: File
    outputSource: sort_bed/sorted_file

  genome_coverage_as_bigwig:
    type: File
    outputSource: convert_bedgraph_to_bigwig/bigwig_file

  macs2_peak_calling_report:
    type: File
    outputSource: call_peaks/macs_log

  macs2_called_peaks_as_narrow_peak:
    type: File
    outputSource: call_peaks/narrow_peak_file

  macs2_called_peaks_merged:
    type: File
    outputSource: merge_peaks/merged_bed_file

  tag_counts_within_merged_peaks:
    type: File
    outputSource: count_tags/intersected_file

  merged_peaks_sequences:
    type: File
    outputSource: get_sequences/sequences_file


steps:


# -----------------------------------------------------------------------------------

  # try to uncompress input fastq file 1
  extract_fastq_1:
    run: ../../tools/extract-fastq.cwl
    in:
      compressed_file: fastq_file_1
    out: [fastq_file]

  # run QC for uncompressed fastq file 1
  run_fastqc_fastq_1:
    run: ../../tools/fastqc.cwl
    in:
      reads_file: extract_fastq_1/fastq_file
    out:
      - summary_file
      - html_file

  # technical step to rename output from QC report for fastq file 1
  rename_fastqc_report_fastq_1:
    run: ../../tools/rename.cwl
    in:
      source_file: run_fastqc_fastq_1/html_file
      target_filename:
        source: fastq_file_1
        valueFrom: $(get_root(self.basename)+"_fastqc_report.html")
    out: [target_file]

  # check if we want to trim adaprters based on QC from fastq file 1
  trigger_adapter_trimming_fastq_1:
    run: ../../tools/fastqc-results-trigger.cwl
    in:
      summary_file: run_fastqc_fastq_1/summary_file
      criteria:
        default: ".*Per base sequence quality.*|.*Per sequence quality scores.*|.*Overrepresented sequences.*|.*Adapter Content.*"
    out: [trigger]


# -----------------------------------------------------------------------------------

  # try to uncompress input fastq file 2
  extract_fastq_2:
    run: ../../tools/extract-fastq.cwl
    in:
      compressed_file: fastq_file_2
    out: [fastq_file]

  # run QC for uncompressed fastq file 2
  run_fastqc_fastq_2:
    run: ../../tools/fastqc.cwl
    in:
      reads_file: extract_fastq_2/fastq_file
    out:
      - summary_file
      - html_file

  # technical step to rename output from QC report for fastq file 2
  rename_fastqc_report_fastq_2:
    run: ../../tools/rename.cwl
    in:
      source_file: run_fastqc_fastq_2/html_file
      target_filename:
        source: fastq_file_2
        valueFrom: $(get_root(self.basename)+"_fastqc_report.html")
    out: [target_file]
  
  # check if we want to trim adaprters based on QC from fastq file 2
  trigger_adapter_trimming_fastq_2:
    run: ../../tools/fastqc-results-trigger.cwl
    in:
      summary_file: run_fastqc_fastq_2/summary_file
      criteria:  # TODO: see what criteria we need to trigger adapter trimming
        default: ".*Per base sequence quality.*|.*Per sequence quality scores.*|.*Overrepresented sequences.*|.*Adapter Content.*"
    out: [trigger]


# -----------------------------------------------------------------------------------

  # trim adapters only when at least one of the input fastq files failed QC
  trim_adapters:
    run: ../../tools/trimgalore.cwl
    in:
      trigger:
        source: [trigger_adapter_trimming_fastq_1/trigger, trigger_adapter_trimming_fastq_2/trigger]
        valueFrom: $(self[0] || self[1])
      input_file: extract_fastq_1/fastq_file
      input_file_pair: extract_fastq_2/fastq_file
      quality:
        default: 30      # TODO: Do we really need 30? The default is 20
      dont_gzip:
        default: true    # should make it faster
      length:
        default: 30      # discard all reads shorter than 30 bp
      paired:
        default: true
    out:
      - trimmed_file
      - trimmed_file_pair
      - report_file
      - report_file_pair


# -----------------------------------------------------------------------------------

  # technical step to rename trimmed fastq file 1
  rename_trimmed_fastq_1:
    run: ../../tools/rename.cwl
    in:
      source_file: trim_adapters/trimmed_file
      target_filename:
        source: fastq_file_1
        valueFrom: $(get_root(self.basename) + ".fastq")
    out: [target_file]

  # technical step to rename trimmed fastq file 2
  rename_trimmed_fastq_2:
    run: ../../tools/rename.cwl
    in:
      source_file: trim_adapters/trimmed_file_pair
      target_filename:
        source: fastq_file_2
        valueFrom: $(get_root(self.basename) + ".fastq")
    out: [target_file]


# -----------------------------------------------------------------------------------


  # Align trimmed fastq files. Skip all multimapped reads. Unmapped reads are not reported.
  align_reads:
    run: ../../tools/star-alignreads.cwl
    in:
      readFilesIn: [rename_trimmed_fastq_1/target_file, rename_trimmed_fastq_2/target_file]
      genomeDir: indices_folder
      outSAMtype:
        default: ["SAM"]
      outSAMunmapped:
        default: "None"      # Do not output unmapped reads
      alignIntronMax:        # TODO: Is it something specific to make STAR work for ATAC-Seq?
        default: 1
      alignEndsType:         # TODO: Is it something specific to make STAR work for ATAC-Seq?
        default: "EndToEnd"
      alignMatesGapMax:      # TODO: Is it something specific to make STAR work for ATAC-Seq?
        default: 2000        
      outFilterMultimapNmax:
        default: 1           # skip all multimapped reads
      outFilterMismatchNmax:
        default: 5           # allow maximum 5 mismatches per read
      outFileNamePrefix:
        source: [rename_trimmed_fastq_1/target_file, rename_trimmed_fastq_2/target_file]
        valueFrom: $(get_root(self[0].basename) + "_" + get_root(self[1].basename) + ".")
      threads: threads
    out:
      - aligned_file
      - uniquely_mapped_reads_number
      - log_final
      - log_progress

  # Sort and index SAM file. Doesn't change the data
  sort_and_index:
    run: ../../tools/samtools-sort-index.cwl
    in:
      sort_input: align_reads/aligned_file
      sort_output_filename:
        source: [rename_trimmed_fastq_1/target_file, rename_trimmed_fastq_2/target_file]
        valueFrom: $(get_root(self[0].basename) + "_" + get_root(self[1].basename) + ".bam")
      threads: threads
    out:
    - bam_bai_pair

  # Get bam statistics before applying any read filters
  get_bam_statistics:
    run: ../../tools/samtools-stats.cwl
    in:
      bambai_pair: sort_and_index/bam_bai_pair
      output_filename:
        source: sort_and_index/bam_bai_pair
        valueFrom: $(get_root(self.basename)+"_bam_statistics_report.txt")
    out:
    - log_file
    - average_length


# -----------------------------------------------------------------------------------

  # Exlude chromosomes we don't need. Returns sorted by coordinates and indexed file
  filter_reads:
    run: ../../tools/samtools-filter.cwl
    in:
      bam_bai_pair: 
      exclude_chromosome: exclude_chromosome
    out:
    - filtered_bam_bai_pair
  
  # Get bam statistics after removing unused chromosomes. We need reads_mapped for scaling
  get_bam_statistics_after_chrom_removal:
    run: ../../tools/samtools-stats.cwl
    in:
      bambai_pair: filter_reads/filtered_bam_bai_pair
    out:
    - reads_mapped

  # Remove PCR duplicates. Returns sorted by coordinates and indexed file
  remove_duplicates:
    run: ../../tools/samtools-markdup.cwl
    in:
      bam_bai_pair: filter_reads/filtered_bam_bai_pair
      threads: threads
    out:
    - deduplicated_bam_bai_pair
    - markdup_report

  # Get bam statistics after applying read filters
  get_bam_statistics_after_filtering:
    run: ../../tools/samtools-stats.cwl
    in:
      bambai_pair: remove_duplicates/deduplicated_bam_bai_pair
      output_filename:
        source: remove_duplicates/deduplicated_bam_bai_pair
        valueFrom: $(get_root(self.basename)+"_bam_statistics_report_after_filtering.txt")
    out:
    - log_file
    - reads_mapped
    - average_length

  # Convert BAM to BED format. All paired-ends became single-reads. We don't split reads by N or D in CIGAR (do we really have them in ATAC?)
  convert_bam_to_bed:
    run: ../../tools/bedtools-bamtobed.cwl
    in:
      bam_file: sort_and_index_after_filtering/bam_bai_pair
    out: [bed_file]

  # Shift reads to Tn5 binding sites. Each read became 40bp long
  shift_reads:
    run: ../../tools/custom-bash.cwl
    in:
      input_file: convert_bam_to_bed/bed_file
      param:
        source: convert_bam_to_bed/bed_file
        valueFrom: $(get_root(self.basename)+"_shifted.bed")
      script:
        default: cat "$0" | awk 'BEGIN {OFS = "\t"} ; {if ($6 == "+") print $1, ($3 + 4) - 20, ($3 + 4) + 20, $4, $5, $6; else print $1, ($2 - 5) - 20, ($2 - 5) + 20, $4, $5, $6}' > $1
    out:
    - output_file

  # Remove all blacklisted regions from Tn5 binding sites
  remove_blacklisted:
    run: ../../tools/bedtools-intersect.cwl
    in:
      file_a: shift_reads/output_file
      file_b: blacklisted_regions_bed
      no_overlaps:
        default: true
    out:
    - intersected_file

  # Sort filtered Tn5 binding sites with -k 1,1 to be able to use it with bedtools genomecov
  sort_bed:
    run: ../tools/linux-sort.cwl
    in:
      unsorted_file: remove_blacklisted/intersected_file
      key:
        default: ["1,1"]
    out:
    - sorted_file

  # Technical step to find the file with chromosome lengths
  get_chr_name_length:
    run: ../../tools/get-file-by-name.cwl
    in:
      input_files: indices_folder
      basename_regex:
        default: "chrNameLength.txt"
    out:
    - selected_file

  # Get genome coverage from Tn5 binding sites
  convert_bed_to_bedgraph:
    run: ../tools/bedtools-genomecov.cwl
    in:
      input_file: sort_bed/sorted_file
      depth:
        default: "-bg"
      mapped_reads_number: get_bam_statistics_after_chrom_removal/reads_mapped  # TODO: do we need to take mapped reads number from STAR?
      chrom_length_file: get_chr_name_length/selected_file
    out:
    - genome_coverage_file

  # sort genome coverage of Tn5 binding sites
  sort_bedgraph:
    run: ../tools/linux-sort.cwl
    in:
      unsorted_file: convert_bed_to_bedgraph/genome_coverage_file
      key:
        default: ["1,1","2,2n"]
    out:
    - sorted_file

  # Convert sorted genome coverage bedgraph file with Tn5 binding sites to bigwig
  convert_bedgraph_to_bigwig:
    run: ../tools/ucsc-bedgraphtobigwig.cwl
    in:
      bedgraph_file: sort_bedgraph/sorted_file
      chrom_length_file: get_chr_name_length/selected_file
    out:
    - bigwig_file


# -----------------------------------------------------------------------------------

  # Call peals with MACS2. Need some explanation of used parameters
  call_peaks:
    run: ../../tools/macs2-callpeak.cwl
    in:
      treatment_file: sort_bed/sorted_file
      format_mode:
        default: "BED"
      genome_size: genome_size
      keep_dup:
        default: "all"
      nomodel:
        default: true
      shift:
        source: get_bam_statistics_after_filtering/average_length
        valueFrom: $(-Math.round(self/2))
      extsize: get_bam_statistics_after_filtering/average_length
    out:
    - narrow_peak_file
    - macs_log

  # Sort called peaks in order to use them with bedtools-merge
  sort_peaks:
    run: ../../tools/linux-sort.cwl
    in:
      unsorted_file: call_peaks/narrow_peak_file
      key:
        default: ["1,1","2,2n"]
    out:
    - sorted_file

  # Merge sorted peaks
  merge_peaks:
    run: ../../tools/bedtools-merge.cwl
    in:
      bed_file: sort_peaks/sorted_file
    out:
    - merged_bed_file

  # Count Tn5 binding sites within merged peaks
  count_tags:
    run: ../../tools/bedtools-intersect.cwl
    in:
      file_a: merge_peaks/merged_bed_file
      file_b: sort_bed/sorted_file
      count:
        default: true
    out:
    - intersected_file

  # Get sequences from the merged peaks
  get_sequences:
    run: ../../tools/bedtools-getfasta.cwl
    in:
      genome_fasta_file: genome_fasta_file
      intervals_file: merge_peaks/merged_bed_file
    out:
    - sequences_file