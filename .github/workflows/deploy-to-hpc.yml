name: Deploy to HPC

on:
  workflow_dispatch:
    inputs:
      docker_tag:
        description: 'Docker tag to deploy'
        required: true
        type: string
        default: 'v0.0.31'
      target_host:
        description: 'Target HPC host'
        required: true
        type: string
        default: 'bmicluster-compute'
  workflow_run:
    workflows: ["Build and Push Docker Image"]
    types:
      - completed
    branches:
      - master
      - main

jobs:
  deploy:
    name: Deploy to HPC
    runs-on: self-hosted
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history to extract the correct tag
      
      - name: Download artifacts if workflow_run triggered
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/github-script@v6
        with:
          script: |
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: ${{ github.event.workflow_run.id }}
            });
            
            const matchArtifact = artifacts.data.artifacts.find(artifact => {
              return artifact.name == "docker-tag"
            });
            
            if (matchArtifact) {
              const download = await github.rest.actions.downloadArtifact({
                owner: context.repo.owner,
                repo: context.repo.repo,
                artifact_id: matchArtifact.id,
                archive_format: 'zip'
              });
              
              const fs = require('fs');
              fs.writeFileSync('docker-tag.zip', Buffer.from(download.data));
              console.log('Artifact downloaded');
              
              const { execSync } = require('child_process');
              execSync('unzip docker-tag.zip');
              const dockerTag = fs.readFileSync('docker_tag.txt', 'utf8').trim();
              console.log(`Using Docker tag from previous workflow: ${dockerTag}`);
              
              // Set output for use in later steps
              core.exportVariable('DOCKER_TAG', dockerTag);
            } else {
              console.log('No docker-tag artifact found, using default tag');
              core.exportVariable('DOCKER_TAG', 'v0.0.31');
            }
            core.exportVariable('TARGET_HOST', 'bmicluster-compute');
      
      - name: Set Docker tag from git or input
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          # Use the input value
          echo "DOCKER_TAG=${{ github.event.inputs.docker_tag }}" >> $GITHUB_ENV
          echo "TARGET_HOST=${{ github.event.inputs.target_host }}" >> $GITHUB_ENV
          
          echo "Using Docker tag: ${{ github.event.inputs.docker_tag }}"
          echo "Using target host: ${{ github.event.inputs.target_host }}"
      
      - name: Display active settings
        run: |
          echo "Using Docker tag: $DOCKER_TAG"
          echo "Using target host: $TARGET_HOST"
      
      - name: Setup SSH key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
        run: |
          set -x  # Echo commands for better debugging
          
          # Create .ssh directory
          mkdir -p ~/.ssh
          
          # Debug: Check if secret is available
          echo "Checking if SSH_PRIVATE_KEY secret is available..."
          if [ -z "$SSH_PRIVATE_KEY" ]; then
            echo "ERROR: SSH_PRIVATE_KEY secret is empty or not set"
            exit 1
          fi
          
          # Create the SSH key with proper format
          printf "%s\n" "$SSH_PRIVATE_KEY" > ~/.ssh/github_action_key
          
          # Debug: Check key file content
          echo "Checking key file content..."
          if [ ! -s ~/.ssh/github_action_key ]; then
            echo "ERROR: Key file is empty"
            exit 1
          fi
          
          # Verify the key format
          if ! grep -q "BEGIN OPENSSH PRIVATE KEY" ~/.ssh/github_action_key; then
            echo "ERROR: Key does not contain proper OpenSSH format"
            echo "First line of key:"
            head -n 1 ~/.ssh/github_action_key
            echo "Last line of key:"
            tail -n 1 ~/.ssh/github_action_key
            echo "Key file size:"
            ls -l ~/.ssh/github_action_key
            exit 1
          fi
          
          # Set proper permissions
          chmod 600 ~/.ssh/github_action_key
          
          # Check key format validity
          echo "Key fingerprint:"
          ssh-keygen -l -f ~/.ssh/github_action_key || {
            echo "ERROR: Invalid key format"
            echo "Key contents (first line):"
            head -n 1 ~/.ssh/github_action_key
            echo "Key file size:"
            ls -l ~/.ssh/github_action_key
            exit 1
          }
          
          # Start SSH agent
          eval $(ssh-agent -s)
          ssh-add -v ~/.ssh/github_action_key || {
            echo "ERROR: Failed to add key to SSH agent"
            echo "SSH agent status:"
            ssh-agent
            echo "Key file permissions:"
            ls -l ~/.ssh/github_action_key
            exit 1
          }
          
          # Create SSH config with the exact configuration needed
          cat > ~/.ssh/config << EOF
          Host bmicluster
            HostName bmiclusterp.chmcres.cchmc.org
            User pavb5f
            IdentityFile ~/.ssh/github_action_key
            IdentitiesOnly yes
            StrictHostKeyChecking no
            UserKnownHostsFile=/dev/null
            LogLevel ERROR
            PreferredAuthentications publickey
            BatchMode yes
            ServerAliveInterval 60
            ServerAliveCountMax 3

          Host bmicluster-compute
            User pavb5f
            HostName bmi-460g10-04.chmcres.cchmc.org
            IdentityFile ~/.ssh/github_action_key
            IdentitiesOnly yes
            StrictHostKeyChecking no
            UserKnownHostsFile=/dev/null
            LogLevel ERROR
            PreferredAuthentications publickey
            BatchMode yes
            ServerAliveInterval 60
            ServerAliveCountMax 3
            ProxyCommand ssh -i ~/.ssh/github_action_key -W %h:%p bmicluster
          EOF
          
          # Set proper permissions for config
          chmod 600 ~/.ssh/config
          
          # Show system information
          echo "=== SYSTEM INFO ==="
          uname -a
          which ssh
          ssh -V
      
      - name: Test SSH connection
        run: |
          # Test direct connection to compute node via ProxyCommand
          echo "Testing SSH connection to bmicluster-compute..."
          
          # Make sure SSH agent is running
          eval $(ssh-agent -s)
          ssh-add ~/.ssh/github_action_key
          
          # Test connection to jump host first (suppress output)
          echo "Testing connection to jump host..."
          ssh -i ~/.ssh/github_action_key -q bmicluster "bash --noprofile --norc -c 'echo \"Jump host connection succeeded\"'" || {
            echo "ERROR: SSH connection to jump host failed"
            exit 1
          }
          
          # Now test connection to compute node (suppress output)
          echo "Testing connection to compute node..."
          ssh -i ~/.ssh/github_action_key -q bmicluster-compute "bash --noprofile --norc -c 'hostname >/dev/null 2>&1 && echo \"SSH_CONNECTION_SUCCESS\"'" || {
            echo "ERROR: SSH connection to compute node failed"
            exit 1
          }
      
      - name: Deploy to HPC
        run: |
          set -x  # Debug mode to show all commands
          
          # Use environment variables
          echo "Deploying docker tag: $DOCKER_TAG to bmicluster-compute..."
          
          # First, verify SSH connection with verbose output
          echo "Testing SSH connection before deployment..."
          if ! ssh -i ~/.ssh/github_action_key -q bmicluster-compute "bash --noprofile --norc -c 'hostname && echo \"SSH connection verified\"'"; then
            echo "ERROR: Cannot connect to compute node for deployment"
            exit 1
          fi
          
          # Check if Singularity is available on the compute node (via module) with more verbose output
          echo "Setting up Singularity on compute node..."
          ssh -i ~/.ssh/github_action_key -q bmicluster-compute "bash --noprofile --norc -c 'export TERM=dumb && export LANG=C && export LC_ALL=C && module list && module avail singularity && module load singularity/3.7.0 && which singularity && singularity --version'" || {
            echo "ERROR: Failed to set up environment on compute node"
            exit 1
          }
          
          # Create deployment script with debug information
          cat > singularity_deploy.sh << 'EOFMARK'
          #!/bin/bash
          set -e
          
          # Set environment variables
          export TERM=dumb
          export LANG=C
          export LC_ALL=C
          
          # Configuration
          IMAGES_DIR="/data/barskilab/scidap_server/singularity_images"
          SINGULARITY_MODULE="singularity/3.7.0"
          LOG_FILE="${IMAGES_DIR}/update_images.log"
          DOCKER_TAG="$1"
          
          # Logging function with timestamp and echo to stdout
          log() {
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
          }
          
          # Error handling function
          handle_error() {
              log "ERROR: $1"
              exit 1
          }
          
          # Start deployment
          log "Starting deployment script for biowardrobe2/scidap-deseq:${DOCKER_TAG}"
          
          # Print debug information
          log "Current user: $(whoami)"
          log "Current directory: $(pwd)"
          log "Module system status:"
          module list 2>&1 | while read line; do log "  $line"; done
          
          # Load Singularity module with verbose logging
          log "Loading Singularity module: $SINGULARITY_MODULE"
          if ! module load "$SINGULARITY_MODULE" 2>&1; then
              handle_error "Failed to load Singularity module"
          fi
          
          # Verify Singularity is available
          if ! which singularity > /dev/null 2>&1; then
              handle_error "Singularity command not found in PATH after loading module"
          fi
          
          log "Singularity version: $(singularity --version)"
          
          # Create images directory if it doesn't exist
          log "Creating/verifying images directory: $IMAGES_DIR"
          mkdir -p "$IMAGES_DIR" || handle_error "Failed to create directory: $IMAGES_DIR"
          
          # Pull the Docker image
          log "Pulling Docker image: biowardrobe2/scidap-deseq:${DOCKER_TAG}"
          if ! singularity pull --force "$IMAGES_DIR/scidap-deseq_${DOCKER_TAG}.sif" "docker://biowardrobe2/scidap-deseq:${DOCKER_TAG}" 2>&1; then
              handle_error "Failed to pull Docker image"
          fi
          
          # Verify the image was created
          log "Verifying image was created"
          if [ ! -f "$IMAGES_DIR/scidap-deseq_${DOCKER_TAG}.sif" ]; then
              handle_error "Singularity image was not created"
          fi
          
          # Set proper permissions
          log "Setting permissions on image file"
          chmod 644 "$IMAGES_DIR/scidap-deseq_${DOCKER_TAG}.sif" || handle_error "Failed to set permissions"
          
          log "Deployment completed successfully"
          log "Image available at: $IMAGES_DIR/scidap-deseq_${DOCKER_TAG}.sif"
          echo "SINGULARITY_DEPLOYMENT_SUCCESS"
          EOFMARK
          
          # Print script content for debugging
          echo "=== DEPLOYMENT SCRIPT CONTENT ==="
          cat singularity_deploy.sh
          echo "=== END OF SCRIPT CONTENT ==="
          
          # Make the script executable
          chmod +x singularity_deploy.sh
          
          # Copy the script to the compute node
          echo "Copying script to compute node..."
          scp -i ~/.ssh/github_action_key -q singularity_deploy.sh bmicluster-compute:/tmp/ || {
            echo "ERROR: Failed to copy deployment script to compute node"
            exit 1
          }
          
          # Execute the script on the compute node with more verbose output
          echo "Executing deployment script on compute node..."
          ssh -i ~/.ssh/github_action_key bmicluster-compute "bash --noprofile --norc -c 'export TERM=dumb && export LANG=C && export LC_ALL=C && cd /tmp && chmod +x singularity_deploy.sh && ./singularity_deploy.sh $DOCKER_TAG'" || {
            echo "ERROR: Deployment failed"
            exit 1
          }
          
          # Verify deployment by checking if the file exists
          echo "Verifying deployment..."
          VERIFY_CMD="ls -la /data/barskilab/scidap_server/singularity_images/scidap-deseq_${DOCKER_TAG}.sif"
          if ssh -i ~/.ssh/github_action_key -q bmicluster-compute "bash --noprofile --norc -c '$VERIFY_CMD'"; then
            echo "✅ Deployment verified! Image exists on target system."
          else
            echo "⚠️ WARNING: Could not verify deployment - image not found"
            echo "Manual verification may be required"
          fi
          
          # Clean up
          echo "Cleaning up temporary files..."
          ssh -i ~/.ssh/github_action_key -q bmicluster-compute "rm -f /tmp/singularity_deploy.sh"
          
          echo "Deployment workflow completed"
      
      - name: Cleanup
        if: always()
        run: |
          rm -f ~/.ssh/github_action_key ~/.ssh/config singularity_deploy.sh 2>/dev/null || true